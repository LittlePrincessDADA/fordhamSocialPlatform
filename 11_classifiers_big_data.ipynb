{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from numpy import savetxt\n",
    "import math\n",
    "\n",
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "import compute_measure\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt, savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median(lst):\n",
    "\tlst = sorted(lst)\n",
    "\tif len(lst) < 1:\n",
    "\t\t\treturn None\n",
    "\tif len(lst) %2 == 1:\n",
    "\t\t\treturn lst[((len(lst)+1)/2)-1]\n",
    "\telse:\n",
    "\t\t\treturn float(sum(lst[(len(lst)/2)-1:(len(lst)/2)+1]))/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "X = np.array(df.drop(['class'],1))\n",
    "y = np.array(df['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)\n",
    "#split 10% of the dataset to test the performance of each classifiers\n",
    "A_train, A_test, b_train, b_test = cross_validation.train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## name list of classifiers\n",
    "names = [\"k-NN\",\n",
    "\t\t \"DecisionTree\",\n",
    "\t\t \"RandomForest\",\n",
    "\t\t \"AdaBoost\",\n",
    "\t\t \"NaiveBayes\",\n",
    "\t\t \"QDA\",\n",
    "\t\t \"Gradient Boosting\",\n",
    "\t\t \"LDA\",\n",
    "\t\t \"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "\t\tKNeighborsClassifier(3),\n",
    "\t\tDecisionTreeClassifier(max_depth=5),\n",
    "\t\tRandomForestClassifier(n_estimators=100, oob_score=True),\n",
    "\t\tAdaBoostClassifier(),\n",
    "\t\tGaussianNB(),\n",
    "\t\tQuadraticDiscriminantAnalysis(),\n",
    "\t\tGradientBoostingClassifier(),\n",
    "\t\tLinearDiscriminantAnalysis(),\n",
    "\t\tMLPClassifier(alpha=1e-5, hidden_layer_sizes=(200, 1),  max_iter=10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Classifiers' Performance on Small Dataset:\n",
      "k-NN\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.99420289855072463, 0.979009235936188, 0.9987449799196787, 0.9957301451750641, 0.9937562437562437]\n",
      "Misclassified Number: 30 out of 5175\n",
      "D: 1.37781463301\n",
      "DecisionTree\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.994975845410628, 0.9848866498740554, 0.9979919678714859, 0.9932260795935648, 0.9954932398597897]\n",
      "Misclassified Number: 26 out of 5175\n",
      "D: 1.3794895908\n",
      "RandomForest\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Misclassified Number: 0 out of 5175\n",
      "D: 1.38629436112\n",
      "AdaBoost\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.99961352657004832, 0.998320738874895, 1.0, 1.0, 0.9994982438534872]\n",
      "Misclassified Number: 1 out of 5175\n",
      "D: 1.3856812023\n",
      "NaiveBayes\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.95903381642512076, 0.9076406381192276, 0.9743975903614458, 0.9137785291631445, 0.9724448897795591]\n",
      "Misclassified Number: 212 out of 5175\n",
      "D: 1.33566455266\n",
      "QDA\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.85198067632850238, 0.9378673383711167, 0.8263052208835341, 0.6174682144831398, 0.978015448603684]\n",
      "Misclassified Number: 766 out of 5175\n",
      "D: 1.24863658698\n",
      "Gradient Boosting\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.99922705314009663, 0.9974811083123426, 0.9997489959839357, 0.9991589571068125, 0.9992473657802308]\n",
      "Misclassified Number: 3 out of 5175\n",
      "D: 1.38521509919\n",
      "LDA\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.96927536231884059, 0.8673383711167086, 0.9997489959839357, 0.9990328820116054, 0.9618449649843033]\n",
      "Misclassified Number: 158 out of 5175\n",
      "D: 1.3370200635\n",
      "MLP\n",
      "accuracy, sen, spec, ppr, npr:\n",
      "[0.76985507246376816, 0.0, 1.0, 9999999999, 0.7698550724637682]\n",
      "Misclassified Number: 1190 out of 5175\n",
      "D: 0.976362771378\n"
     ]
    }
   ],
   "source": [
    "classifier_no = len(classifiers)\n",
    "\n",
    "misclassified_number_list= []\n",
    "\n",
    "copy_names = list(names)\n",
    "predictions = []\n",
    "answers = []\n",
    "\n",
    "print(\"\\nAnalyzing Classifiers' Performance on Small Dataset:\")\n",
    "for name, clf in zip(names, classifiers):\n",
    "\tclf.fit(A_train, b_train)\n",
    "\tpred = clf.predict(A_test)\n",
    "\tpredictions.append(pred)\n",
    "\tans = compute_measure.compute_measure(pred, b_test)\n",
    "\tanswers.append(ans)\n",
    "\taccuracy = ans[0]\n",
    "\tsen = ans[1]\n",
    "\tspec = ans[2]\n",
    "\tprint(name)\n",
    "\tprint(\"accuracy, sen, spec, ppr, npr:\")\n",
    "\tprint(\"{}\".format(ans))\n",
    "\tmisclassified_number = (b_test.size)*(1-accuracy)\n",
    "\tprint(\"Misclassified Number: {} out of {}\".format(int(misclassified_number), b_test.size))\n",
    "\tmisclassified_number_list.append(int(misclassified_number))\n",
    "\td = math.log(1+accuracy)+math.log(1+(float(sen+spec)/2))\n",
    "\tprint(\"D: {}\".format(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three Classifiers\n",
      "RandomForest\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Misclassified Number: 0 out of 5175\n",
      "AdaBoost\n",
      "[0.99961352657004832, 0.998320738874895, 1.0, 1.0, 0.9994982438534872]\n",
      "Misclassified Number: 1 out of 5175\n",
      "Gradient Boosting\n",
      "[0.99922705314009663, 0.9974811083123426, 0.9997489959839357, 0.9991589571068125, 0.9992473657802308]\n",
      "Misclassified Number: 3 out of 5175\n"
     ]
    }
   ],
   "source": [
    "new_classifiers = sorted(zip(misclassified_number_list, copy_names, classifiers, predictions, answers))[:3]\n",
    "\n",
    "print(\"Top Three Classifiers\")\n",
    "\n",
    "prediction_results = []\n",
    "for misclassified_number, name, clf, pred, ans in new_classifiers:\n",
    "\tprint(name)\n",
    "\tprint(\"{}\".format(ans))\n",
    "\tprint(\"Misclassified Number: {} out of {}\".format(int(misclassified_number), b_test.size))\n",
    "\tprediction_results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "[0.9992270830112846, 0.998022412656559, 0.9995961227786753, 0.9986807387862797, 0.9993943064809206]\n",
      "4\n",
      "Misclassified Number: 4 out of 6469\n",
      "D: 1.38531228449\n",
      "AdaBoost\n",
      "[0.9992270830112846, 0.998022412656559, 0.9995961227786753, 0.9986807387862797, 0.9993943064809206]\n",
      "4\n",
      "Misclassified Number: 4 out of 6469\n",
      "D: 1.38531228449\n",
      "Gradient Boosting\n",
      "[0.9992270830112846, 0.998022412656559, 0.9995961227786753, 0.9986807387862797, 0.9993943064809206]\n",
      "4\n",
      "Misclassified Number: 4 out of 6469\n",
      "D: 1.38531228449\n"
     ]
    }
   ],
   "source": [
    "prediction_results = []\n",
    "\n",
    "for misclassified_number, name, clf, pred, ans in new_classifiers:\n",
    "\tprint(name)\n",
    "\tclf.fit(X_train, y_train)\n",
    "\tpred = clf.predict(X_test)\n",
    "\tprediction_results.append(pred)\n",
    "\tans = compute_measure.compute_measure(pred, y_test)\n",
    "\tprint(\"{}\".format(ans))\n",
    "\tprint(int(y_test.size * (1-ans[0])))\n",
    "\tprint(\"Misclassified Number: {} out of {}\".format(int(y_test.size * (1-ans[0])), y_test.size))\n",
    "\taccuracy = ans[0]\n",
    "\tsen = ans[1]\n",
    "\tspec = ans[2]\n",
    "\td = math.log(1+accuracy)+math.log(1+(float(sen+spec)/2))\n",
    "\tprint(\"D: {}\".format(d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
